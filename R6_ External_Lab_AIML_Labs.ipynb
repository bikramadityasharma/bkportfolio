{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "### A MNIST-like fashion product database\n",
    "\n",
    "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efNjNImfOIUC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9C4aAIGOIUH",
    "outputId": "5ef9aff6-a7bd-4b26-cba6-8750955f6ca3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA1WsFSeOIUS"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnbx7TyQOIUY"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbiHj5YPOIUc",
    "outputId": "87e1b9cd-07f0-45cb-e706-0d51ad742d72",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(testY))\n",
    "test_label = testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDAYzkwyOIUj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convert both training and testing labels into one-hot vectors.\n",
    "\n",
    "**Hint:** check **tf.keras.utils.to_categorical()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBlfYlANOIUk"
   },
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHV3b9mzOIUq",
    "outputId": "27bdfe58-91ee-4677-fe49-e742ad306c70",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print('First 5 examples now are: ', trainY[0:5])\n",
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwhQ8e7VOIUw"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot first 10 images in the triaining set and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX/255.0\n",
    "testX = testX/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvDML2OoOIUx",
    "outputId": "9dafc94e-61a8-4089-be03-d143163d68aa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(trainX[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[test_label[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4TbJGeSOIU4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac06XZZTOIU6"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Add OUTPUT layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQpLv3aOIU_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O59C_-IgOIVB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 13s 209us/sample - loss: 0.7787 - accuracy: 0.7518 - val_loss: 0.6250 - val_accuracy: 0.7919\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.5686 - accuracy: 0.8134 - val_loss: 0.5677 - val_accuracy: 0.8082\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.5239 - accuracy: 0.8263 - val_loss: 0.5359 - val_accuracy: 0.8191\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.4995 - accuracy: 0.8335 - val_loss: 0.5170 - val_accuracy: 0.8240\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.4838 - accuracy: 0.8377 - val_loss: 0.5059 - val_accuracy: 0.8309\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.4723 - accuracy: 0.8411 - val_loss: 0.4988 - val_accuracy: 0.8285\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.4634 - accuracy: 0.8429 - val_loss: 0.4918 - val_accuracy: 0.8296\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.4562 - accuracy: 0.8460 - val_loss: 0.4871 - val_accuracy: 0.8303\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.4505 - accuracy: 0.8470 - val_loss: 0.4805 - val_accuracy: 0.8310\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.4457 - accuracy: 0.8484 - val_loss: 0.4750 - val_accuracy: 0.8364\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.4414 - accuracy: 0.8501 - val_loss: 0.4784 - val_accuracy: 0.8345\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.4376 - accuracy: 0.8505 - val_loss: 0.4738 - val_accuracy: 0.8349\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.4344 - accuracy: 0.8525 - val_loss: 0.4692 - val_accuracy: 0.8375\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.4314 - accuracy: 0.8527 - val_loss: 0.4648 - val_accuracy: 0.8373\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.4290 - accuracy: 0.8540 - val_loss: 0.4644 - val_accuracy: 0.8383\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.4264 - accuracy: 0.8553 - val_loss: 0.4656 - val_accuracy: 0.8347\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.4241 - accuracy: 0.8560 - val_loss: 0.4613 - val_accuracy: 0.8388\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.4220 - accuracy: 0.8558 - val_loss: 0.4593 - val_accuracy: 0.8388\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.4204 - accuracy: 0.8570 - val_loss: 0.4614 - val_accuracy: 0.8355\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 9s 153us/sample - loss: 0.4186 - accuracy: 0.8575 - val_loss: 0.4617 - val_accuracy: 0.8372\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.4168 - accuracy: 0.8582 - val_loss: 0.4568 - val_accuracy: 0.8405\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.4155 - accuracy: 0.8578 - val_loss: 0.4543 - val_accuracy: 0.8383\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.4142 - accuracy: 0.8586 - val_loss: 0.4525 - val_accuracy: 0.8409\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.4125 - accuracy: 0.8586 - val_loss: 0.4569 - val_accuracy: 0.8394\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.4116 - accuracy: 0.8599 - val_loss: 0.4554 - val_accuracy: 0.8392\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.4105 - accuracy: 0.8592 - val_loss: 0.4551 - val_accuracy: 0.8410\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.4091 - accuracy: 0.8594 - val_loss: 0.4498 - val_accuracy: 0.8422\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.4083 - accuracy: 0.8612 - val_loss: 0.4505 - val_accuracy: 0.8426\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.4070 - accuracy: 0.8610 - val_loss: 0.4503 - val_accuracy: 0.8410\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.4062 - accuracy: 0.8610 - val_loss: 0.4477 - val_accuracy: 0.8439\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.4051 - accuracy: 0.8608 - val_loss: 0.4475 - val_accuracy: 0.8411\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.4043 - accuracy: 0.8619 - val_loss: 0.4469 - val_accuracy: 0.8419\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.4038 - accuracy: 0.8617 - val_loss: 0.4463 - val_accuracy: 0.8433\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.4025 - accuracy: 0.8616 - val_loss: 0.4461 - val_accuracy: 0.8437\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.4023 - accuracy: 0.8618 - val_loss: 0.4446 - val_accuracy: 0.8435\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.4009 - accuracy: 0.8628 - val_loss: 0.4470 - val_accuracy: 0.8428\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.4004 - accuracy: 0.8627 - val_loss: 0.4454 - val_accuracy: 0.8433\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.3998 - accuracy: 0.8626 - val_loss: 0.4450 - val_accuracy: 0.8414\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.3992 - accuracy: 0.8635 - val_loss: 0.4441 - val_accuracy: 0.8440\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3985 - accuracy: 0.8631 - val_loss: 0.4452 - val_accuracy: 0.8439\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.3977 - accuracy: 0.8643 - val_loss: 0.4444 - val_accuracy: 0.8443\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3974 - accuracy: 0.8636 - val_loss: 0.4485 - val_accuracy: 0.8438\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3965 - accuracy: 0.8635 - val_loss: 0.4464 - val_accuracy: 0.8425\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 9s 145us/sample - loss: 0.3960 - accuracy: 0.8641 - val_loss: 0.4423 - val_accuracy: 0.8446\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3953 - accuracy: 0.8643 - val_loss: 0.4456 - val_accuracy: 0.8429\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3952 - accuracy: 0.8646 - val_loss: 0.4437 - val_accuracy: 0.8434\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.3941 - accuracy: 0.8649 - val_loss: 0.4404 - val_accuracy: 0.8446\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3943 - accuracy: 0.8647 - val_loss: 0.4414 - val_accuracy: 0.8430\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3934 - accuracy: 0.8655 - val_loss: 0.4430 - val_accuracy: 0.8430\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.3928 - accuracy: 0.8657 - val_loss: 0.4409 - val_accuracy: 0.8438\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.3922 - accuracy: 0.8649 - val_loss: 0.4417 - val_accuracy: 0.8425\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.3920 - accuracy: 0.8647 - val_loss: 0.4414 - val_accuracy: 0.8446\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.3915 - accuracy: 0.8653 - val_loss: 0.4398 - val_accuracy: 0.8439\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.3908 - accuracy: 0.8659 - val_loss: 0.4416 - val_accuracy: 0.8445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.3905 - accuracy: 0.8661 - val_loss: 0.4402 - val_accuracy: 0.8437\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.3902 - accuracy: 0.8655 - val_loss: 0.4458 - val_accuracy: 0.8418\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 8s 136us/sample - loss: 0.3901 - accuracy: 0.8655 - val_loss: 0.4408 - val_accuracy: 0.8443\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3894 - accuracy: 0.8654 - val_loss: 0.4411 - val_accuracy: 0.8432\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3888 - accuracy: 0.8661 - val_loss: 0.4423 - val_accuracy: 0.8433\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.3886 - accuracy: 0.8662 - val_loss: 0.4405 - val_accuracy: 0.8451\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.3881 - accuracy: 0.8664 - val_loss: 0.4379 - val_accuracy: 0.8452\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3879 - accuracy: 0.8670 - val_loss: 0.4442 - val_accuracy: 0.8426\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.3875 - accuracy: 0.8662 - val_loss: 0.4380 - val_accuracy: 0.8450\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.3870 - accuracy: 0.8660 - val_loss: 0.4408 - val_accuracy: 0.8431\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3866 - accuracy: 0.8669 - val_loss: 0.4376 - val_accuracy: 0.8456\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.3861 - accuracy: 0.8669 - val_loss: 0.4442 - val_accuracy: 0.8397\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.3859 - accuracy: 0.8669 - val_loss: 0.4377 - val_accuracy: 0.8440\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3859 - accuracy: 0.8667 - val_loss: 0.4397 - val_accuracy: 0.8435\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.3855 - accuracy: 0.8673 - val_loss: 0.4419 - val_accuracy: 0.8421\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.3852 - accuracy: 0.8670 - val_loss: 0.4391 - val_accuracy: 0.8445\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.3844 - accuracy: 0.8674 - val_loss: 0.4386 - val_accuracy: 0.8443\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.3846 - accuracy: 0.8668 - val_loss: 0.4378 - val_accuracy: 0.8442\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.3846 - accuracy: 0.8670 - val_loss: 0.4374 - val_accuracy: 0.8441\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.3838 - accuracy: 0.8675 - val_loss: 0.4380 - val_accuracy: 0.8447\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.3837 - accuracy: 0.8669 - val_loss: 0.4478 - val_accuracy: 0.8414\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.3833 - accuracy: 0.8669 - val_loss: 0.4376 - val_accuracy: 0.8458\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.3828 - accuracy: 0.8677 - val_loss: 0.4390 - val_accuracy: 0.8441\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.3831 - accuracy: 0.8675 - val_loss: 0.4374 - val_accuracy: 0.8442\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.3828 - accuracy: 0.8670 - val_loss: 0.4389 - val_accuracy: 0.8440\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.3822 - accuracy: 0.8674 - val_loss: 0.4358 - val_accuracy: 0.8454\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.3819 - accuracy: 0.8674 - val_loss: 0.4381 - val_accuracy: 0.8439\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.3820 - accuracy: 0.8676 - val_loss: 0.4373 - val_accuracy: 0.8446\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3815 - accuracy: 0.8677 - val_loss: 0.4362 - val_accuracy: 0.8443\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.3812 - accuracy: 0.8687 - val_loss: 0.4362 - val_accuracy: 0.8452\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.3811 - accuracy: 0.8679 - val_loss: 0.4371 - val_accuracy: 0.8441\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.3812 - accuracy: 0.8674 - val_loss: 0.4360 - val_accuracy: 0.8447\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.3805 - accuracy: 0.8682 - val_loss: 0.4368 - val_accuracy: 0.8443\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.3803 - accuracy: 0.8687 - val_loss: 0.4357 - val_accuracy: 0.8452\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 10s 175us/sample - loss: 0.3803 - accuracy: 0.8690 - val_loss: 0.4379 - val_accuracy: 0.8435\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3802 - accuracy: 0.8689 - val_loss: 0.4377 - val_accuracy: 0.8441\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.3796 - accuracy: 0.8690 - val_loss: 0.4376 - val_accuracy: 0.8442\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.3792 - accuracy: 0.8690 - val_loss: 0.4352 - val_accuracy: 0.8455\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 9s 153us/sample - loss: 0.3791 - accuracy: 0.8687 - val_loss: 0.4423 - val_accuracy: 0.8441\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.3790 - accuracy: 0.8690 - val_loss: 0.4399 - val_accuracy: 0.8430\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 8s 126us/sample - loss: 0.3790 - accuracy: 0.8688 - val_loss: 0.4395 - val_accuracy: 0.8427\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 8s 140us/sample - loss: 0.3785 - accuracy: 0.8696 - val_loss: 0.4362 - val_accuracy: 0.8453\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.3781 - accuracy: 0.8686 - val_loss: 0.4434 - val_accuracy: 0.8436\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.3783 - accuracy: 0.8694 - val_loss: 0.4386 - val_accuracy: 0.8435\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.3780 - accuracy: 0.8690 - val_loss: 0.4390 - val_accuracy: 0.8428\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.3778 - accuracy: 0.8691 - val_loss: 0.4360 - val_accuracy: 0.8441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ffde753240>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX,trainY,          \n",
    "          validation_data=(testX,testY),\n",
    "          epochs=100,\n",
    "          batch_size=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdzDtGwDOIVF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kndfpdidOIVI"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model2 = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model2.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Normalize the data\n",
    "model2.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add OUTPUT layer\n",
    "model2.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the model\n",
    "model2.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwk3T5LJOIVN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNLR8tcBOIVP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.5160 - accuracy: 0.8232 - val_loss: 0.5108 - val_accuracy: 0.8231\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.4844 - accuracy: 0.8342 - val_loss: 0.4934 - val_accuracy: 0.8268\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.4671 - accuracy: 0.8401 - val_loss: 0.4844 - val_accuracy: 0.8321\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4556 - accuracy: 0.8446 - val_loss: 0.4768 - val_accuracy: 0.8331\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4478 - accuracy: 0.8471 - val_loss: 0.4712 - val_accuracy: 0.8354\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4416 - accuracy: 0.8487 - val_loss: 0.4668 - val_accuracy: 0.8360\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4372 - accuracy: 0.8502 - val_loss: 0.4640 - val_accuracy: 0.8384\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4320 - accuracy: 0.8523 - val_loss: 0.4627 - val_accuracy: 0.8387\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4289 - accuracy: 0.8531 - val_loss: 0.4608 - val_accuracy: 0.8383\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4250 - accuracy: 0.8551 - val_loss: 0.4575 - val_accuracy: 0.8411\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4219 - accuracy: 0.8557 - val_loss: 0.4584 - val_accuracy: 0.8391\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4200 - accuracy: 0.8558 - val_loss: 0.4547 - val_accuracy: 0.8425\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.4170 - accuracy: 0.8561 - val_loss: 0.4540 - val_accuracy: 0.8418\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4146 - accuracy: 0.8576 - val_loss: 0.4523 - val_accuracy: 0.8415\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.4135 - accuracy: 0.8583 - val_loss: 0.4533 - val_accuracy: 0.8417\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4117 - accuracy: 0.8585 - val_loss: 0.4523 - val_accuracy: 0.8416\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4097 - accuracy: 0.8594 - val_loss: 0.4507 - val_accuracy: 0.8419\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4083 - accuracy: 0.8595 - val_loss: 0.4520 - val_accuracy: 0.8418\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4070 - accuracy: 0.8605 - val_loss: 0.4493 - val_accuracy: 0.8410\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.4045 - accuracy: 0.8611 - val_loss: 0.4497 - val_accuracy: 0.8413\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.4054 - accuracy: 0.8599 - val_loss: 0.4484 - val_accuracy: 0.8424\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.4051 - accuracy: 0.8607 - val_loss: 0.4466 - val_accuracy: 0.8441\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.4022 - accuracy: 0.8610 - val_loss: 0.4478 - val_accuracy: 0.8431\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4014 - accuracy: 0.8622 - val_loss: 0.4488 - val_accuracy: 0.8412\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4014 - accuracy: 0.8620 - val_loss: 0.4469 - val_accuracy: 0.8446\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3991 - accuracy: 0.8630 - val_loss: 0.4492 - val_accuracy: 0.8415\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3991 - accuracy: 0.8632 - val_loss: 0.4458 - val_accuracy: 0.8450\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3984 - accuracy: 0.8627 - val_loss: 0.4460 - val_accuracy: 0.8436\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.3965 - accuracy: 0.8622 - val_loss: 0.4494 - val_accuracy: 0.8415\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3960 - accuracy: 0.8641 - val_loss: 0.4458 - val_accuracy: 0.8455\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3957 - accuracy: 0.8625 - val_loss: 0.4456 - val_accuracy: 0.8436\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3946 - accuracy: 0.8646 - val_loss: 0.4456 - val_accuracy: 0.8441\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.3949 - accuracy: 0.8638 - val_loss: 0.4456 - val_accuracy: 0.8448\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3924 - accuracy: 0.8647 - val_loss: 0.4453 - val_accuracy: 0.8440\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3937 - accuracy: 0.8636 - val_loss: 0.4444 - val_accuracy: 0.8441\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.3920 - accuracy: 0.8640 - val_loss: 0.4462 - val_accuracy: 0.8442\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3915 - accuracy: 0.8641 - val_loss: 0.4455 - val_accuracy: 0.8445\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3912 - accuracy: 0.8658 - val_loss: 0.4457 - val_accuracy: 0.8424\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3905 - accuracy: 0.8646 - val_loss: 0.4448 - val_accuracy: 0.8453\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3913 - accuracy: 0.8647 - val_loss: 0.4456 - val_accuracy: 0.8424\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3896 - accuracy: 0.8644 - val_loss: 0.4447 - val_accuracy: 0.8432\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3896 - accuracy: 0.8655 - val_loss: 0.4453 - val_accuracy: 0.8439\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3887 - accuracy: 0.8656 - val_loss: 0.4449 - val_accuracy: 0.8449\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3891 - accuracy: 0.8658 - val_loss: 0.4458 - val_accuracy: 0.8436\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3869 - accuracy: 0.8647 - val_loss: 0.4437 - val_accuracy: 0.8451\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3871 - accuracy: 0.8649 - val_loss: 0.4449 - val_accuracy: 0.8454\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3865 - accuracy: 0.8661 - val_loss: 0.4436 - val_accuracy: 0.8462\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3871 - accuracy: 0.8662 - val_loss: 0.4431 - val_accuracy: 0.8456\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.3851 - accuracy: 0.8672 - val_loss: 0.4439 - val_accuracy: 0.8451\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.3850 - accuracy: 0.8665 - val_loss: 0.4455 - val_accuracy: 0.8453\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.3865 - accuracy: 0.8659 - val_loss: 0.4450 - val_accuracy: 0.8447\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.3840 - accuracy: 0.8667 - val_loss: 0.4454 - val_accuracy: 0.8462\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.3835 - accuracy: 0.8656 - val_loss: 0.4428 - val_accuracy: 0.8455\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3836 - accuracy: 0.8665 - val_loss: 0.4451 - val_accuracy: 0.8444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3842 - accuracy: 0.8671 - val_loss: 0.4438 - val_accuracy: 0.8445\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.3833 - accuracy: 0.8674 - val_loss: 0.4453 - val_accuracy: 0.8425\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3832 - accuracy: 0.8673 - val_loss: 0.4429 - val_accuracy: 0.8449\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3831 - accuracy: 0.8657 - val_loss: 0.4438 - val_accuracy: 0.8453\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.3825 - accuracy: 0.8675 - val_loss: 0.4465 - val_accuracy: 0.8453\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3819 - accuracy: 0.8668 - val_loss: 0.4438 - val_accuracy: 0.8447\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3835 - accuracy: 0.8668 - val_loss: 0.4432 - val_accuracy: 0.8460\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.3816 - accuracy: 0.8673 - val_loss: 0.4451 - val_accuracy: 0.8456\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3820 - accuracy: 0.8667 - val_loss: 0.4430 - val_accuracy: 0.8447\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.3813 - accuracy: 0.8671 - val_loss: 0.4450 - val_accuracy: 0.8460\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.3797 - accuracy: 0.8670 - val_loss: 0.4442 - val_accuracy: 0.8446\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3807 - accuracy: 0.8666 - val_loss: 0.4458 - val_accuracy: 0.8434\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3800 - accuracy: 0.8676 - val_loss: 0.4442 - val_accuracy: 0.8455\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3799 - accuracy: 0.8677 - val_loss: 0.4441 - val_accuracy: 0.8462\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3799 - accuracy: 0.8678 - val_loss: 0.4447 - val_accuracy: 0.8458\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3809 - accuracy: 0.8665 - val_loss: 0.4448 - val_accuracy: 0.8441\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3782 - accuracy: 0.8680 - val_loss: 0.4451 - val_accuracy: 0.8432\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3775 - accuracy: 0.8689 - val_loss: 0.4439 - val_accuracy: 0.8460\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3785 - accuracy: 0.8679 - val_loss: 0.4444 - val_accuracy: 0.8458\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3780 - accuracy: 0.8678 - val_loss: 0.4451 - val_accuracy: 0.8458\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3774 - accuracy: 0.8686 - val_loss: 0.4506 - val_accuracy: 0.8416\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3790 - accuracy: 0.8672 - val_loss: 0.4445 - val_accuracy: 0.8466\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3778 - accuracy: 0.8684 - val_loss: 0.4465 - val_accuracy: 0.8429\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3764 - accuracy: 0.8684 - val_loss: 0.4452 - val_accuracy: 0.8448\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3774 - accuracy: 0.8673 - val_loss: 0.4457 - val_accuracy: 0.8435\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3773 - accuracy: 0.8683 - val_loss: 0.4462 - val_accuracy: 0.8440\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3773 - accuracy: 0.8689 - val_loss: 0.4473 - val_accuracy: 0.8444\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3776 - accuracy: 0.8686 - val_loss: 0.4442 - val_accuracy: 0.8463\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3753 - accuracy: 0.8690 - val_loss: 0.4446 - val_accuracy: 0.8448\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3767 - accuracy: 0.8679 - val_loss: 0.4439 - val_accuracy: 0.8463\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3759 - accuracy: 0.8681 - val_loss: 0.4440 - val_accuracy: 0.8462\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.3772 - accuracy: 0.8692 - val_loss: 0.4441 - val_accuracy: 0.8453\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3752 - accuracy: 0.8685 - val_loss: 0.4448 - val_accuracy: 0.8435\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.3754 - accuracy: 0.8688 - val_loss: 0.4444 - val_accuracy: 0.8460\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.3761 - accuracy: 0.8676 - val_loss: 0.4458 - val_accuracy: 0.8439\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3747 - accuracy: 0.8677 - val_loss: 0.4449 - val_accuracy: 0.8457\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.3739 - accuracy: 0.8697 - val_loss: 0.4449 - val_accuracy: 0.8450\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3747 - accuracy: 0.8691 - val_loss: 0.4442 - val_accuracy: 0.8459\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3749 - accuracy: 0.8693 - val_loss: 0.4454 - val_accuracy: 0.8431\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3742 - accuracy: 0.8693 - val_loss: 0.4456 - val_accuracy: 0.8446\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3741 - accuracy: 0.8695 - val_loss: 0.4459 - val_accuracy: 0.8445\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.3750 - accuracy: 0.8689 - val_loss: 0.4457 - val_accuracy: 0.8457\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3740 - accuracy: 0.8684 - val_loss: 0.4468 - val_accuracy: 0.8435\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.3738 - accuracy: 0.8687 - val_loss: 0.4450 - val_accuracy: 0.8461\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3738 - accuracy: 0.8696 - val_loss: 0.4463 - val_accuracy: 0.8444\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3737 - accuracy: 0.8686 - val_loss: 0.4444 - val_accuracy: 0.8460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ff80de7080>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(trainX,trainY,          \n",
    "          validation_data=(testX,testY),\n",
    "          epochs=100,\n",
    "          batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-KwkmjOIVU"
   },
   "source": [
    "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLXUE9jWOIVV"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model3 = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model3.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Normalize the data\n",
    "model3.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add OUTPUT layer\n",
    "model3.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)\n",
    "\n",
    "#Compile the model\n",
    "model3.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJUqA5T4OIVc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 1.2422 - accuracy: 0.5731 - val_loss: 0.8814 - val_accuracy: 0.6931\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.7976 - accuracy: 0.7236 - val_loss: 0.7510 - val_accuracy: 0.7362\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.7064 - accuracy: 0.7560 - val_loss: 0.6895 - val_accuracy: 0.7589\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.6569 - accuracy: 0.7714 - val_loss: 0.6523 - val_accuracy: 0.7719\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.6256 - accuracy: 0.7827 - val_loss: 0.6266 - val_accuracy: 0.7819\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.6023 - accuracy: 0.7893 - val_loss: 0.6073 - val_accuracy: 0.7889\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.5855 - accuracy: 0.7962 - val_loss: 0.5931 - val_accuracy: 0.7955\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.5708 - accuracy: 0.8019 - val_loss: 0.5809 - val_accuracy: 0.7993\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.5590 - accuracy: 0.8057 - val_loss: 0.5715 - val_accuracy: 0.8020\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.5486 - accuracy: 0.8096 - val_loss: 0.5635 - val_accuracy: 0.8055\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.5405 - accuracy: 0.8138 - val_loss: 0.5561 - val_accuracy: 0.8076\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.5334 - accuracy: 0.8143 - val_loss: 0.5498 - val_accuracy: 0.8084\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.5270 - accuracy: 0.8178 - val_loss: 0.5442 - val_accuracy: 0.8113\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.5206 - accuracy: 0.8193 - val_loss: 0.5390 - val_accuracy: 0.8128\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.5155 - accuracy: 0.8212 - val_loss: 0.5351 - val_accuracy: 0.8125\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.5120 - accuracy: 0.8236 - val_loss: 0.5312 - val_accuracy: 0.8142\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.5065 - accuracy: 0.8248 - val_loss: 0.5270 - val_accuracy: 0.8157\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.5027 - accuracy: 0.8267 - val_loss: 0.5243 - val_accuracy: 0.8169\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.4994 - accuracy: 0.8270 - val_loss: 0.5207 - val_accuracy: 0.8176\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.4953 - accuracy: 0.8298 - val_loss: 0.5182 - val_accuracy: 0.8188\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4941 - accuracy: 0.8286 - val_loss: 0.5155 - val_accuracy: 0.8178\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.4912 - accuracy: 0.8313 - val_loss: 0.5129 - val_accuracy: 0.8202\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.4884 - accuracy: 0.8309 - val_loss: 0.5112 - val_accuracy: 0.8211\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.4852 - accuracy: 0.8328 - val_loss: 0.5091 - val_accuracy: 0.8208\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.4837 - accuracy: 0.8339 - val_loss: 0.5068 - val_accuracy: 0.8225\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.4811 - accuracy: 0.8347 - val_loss: 0.5049 - val_accuracy: 0.8218\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4786 - accuracy: 0.8357 - val_loss: 0.5032 - val_accuracy: 0.8226\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4770 - accuracy: 0.8357 - val_loss: 0.5015 - val_accuracy: 0.8234\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4741 - accuracy: 0.8373 - val_loss: 0.5001 - val_accuracy: 0.8234\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.4726 - accuracy: 0.8370 - val_loss: 0.4978 - val_accuracy: 0.8244\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.4709 - accuracy: 0.8374 - val_loss: 0.4970 - val_accuracy: 0.8247\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.4693 - accuracy: 0.8393 - val_loss: 0.4958 - val_accuracy: 0.8251\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4679 - accuracy: 0.8394 - val_loss: 0.4943 - val_accuracy: 0.8254\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.4661 - accuracy: 0.8395 - val_loss: 0.4929 - val_accuracy: 0.8264\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.4649 - accuracy: 0.8395 - val_loss: 0.4918 - val_accuracy: 0.8259\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4627 - accuracy: 0.8404 - val_loss: 0.4906 - val_accuracy: 0.8270\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.4626 - accuracy: 0.8414 - val_loss: 0.4898 - val_accuracy: 0.8273\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4606 - accuracy: 0.8416 - val_loss: 0.4886 - val_accuracy: 0.8276\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4594 - accuracy: 0.8428 - val_loss: 0.4877 - val_accuracy: 0.8275\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4596 - accuracy: 0.8422 - val_loss: 0.4869 - val_accuracy: 0.8282\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4577 - accuracy: 0.8428 - val_loss: 0.4857 - val_accuracy: 0.8276\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4561 - accuracy: 0.8442 - val_loss: 0.4847 - val_accuracy: 0.8285\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4553 - accuracy: 0.8432 - val_loss: 0.4845 - val_accuracy: 0.8285\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4553 - accuracy: 0.8434 - val_loss: 0.4833 - val_accuracy: 0.8291\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.4529 - accuracy: 0.8435 - val_loss: 0.4825 - val_accuracy: 0.8292\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4518 - accuracy: 0.8440 - val_loss: 0.4818 - val_accuracy: 0.8292\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4508 - accuracy: 0.8449 - val_loss: 0.4810 - val_accuracy: 0.8291\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4506 - accuracy: 0.8443 - val_loss: 0.4800 - val_accuracy: 0.8290\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4485 - accuracy: 0.8463 - val_loss: 0.4796 - val_accuracy: 0.8304\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4477 - accuracy: 0.8467 - val_loss: 0.4790 - val_accuracy: 0.8307\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.4480 - accuracy: 0.8459 - val_loss: 0.4783 - val_accuracy: 0.8303\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4460 - accuracy: 0.8467 - val_loss: 0.4777 - val_accuracy: 0.8309\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4444 - accuracy: 0.8481 - val_loss: 0.4768 - val_accuracy: 0.8300\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4444 - accuracy: 0.8474 - val_loss: 0.4767 - val_accuracy: 0.8305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.4448 - accuracy: 0.8474 - val_loss: 0.4763 - val_accuracy: 0.8301\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4434 - accuracy: 0.8465 - val_loss: 0.4754 - val_accuracy: 0.8302\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.4430 - accuracy: 0.8488 - val_loss: 0.4744 - val_accuracy: 0.8309\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.4423 - accuracy: 0.8472 - val_loss: 0.4747 - val_accuracy: 0.8307\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4417 - accuracy: 0.8484 - val_loss: 0.4738 - val_accuracy: 0.8309\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.4409 - accuracy: 0.8483 - val_loss: 0.4733 - val_accuracy: 0.8315\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.4414 - accuracy: 0.8492 - val_loss: 0.4725 - val_accuracy: 0.8309\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.4391 - accuracy: 0.8487 - val_loss: 0.4722 - val_accuracy: 0.8318\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.4396 - accuracy: 0.8497 - val_loss: 0.4717 - val_accuracy: 0.8315\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.4384 - accuracy: 0.8493 - val_loss: 0.4715 - val_accuracy: 0.8324\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.4371 - accuracy: 0.8490 - val_loss: 0.4710 - val_accuracy: 0.8327\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.4375 - accuracy: 0.8504 - val_loss: 0.4711 - val_accuracy: 0.8329\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.4366 - accuracy: 0.8497 - val_loss: 0.4705 - val_accuracy: 0.8326\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.4359 - accuracy: 0.8507 - val_loss: 0.4697 - val_accuracy: 0.8325\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.4351 - accuracy: 0.8506 - val_loss: 0.4695 - val_accuracy: 0.8335\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4362 - accuracy: 0.8508 - val_loss: 0.4692 - val_accuracy: 0.8341\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.4341 - accuracy: 0.8508 - val_loss: 0.4689 - val_accuracy: 0.8338\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.4325 - accuracy: 0.8512 - val_loss: 0.4684 - val_accuracy: 0.8335\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.4331 - accuracy: 0.8513 - val_loss: 0.4677 - val_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4332 - accuracy: 0.8508 - val_loss: 0.4676 - val_accuracy: 0.8337\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.4319 - accuracy: 0.8522 - val_loss: 0.4675 - val_accuracy: 0.8343\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4324 - accuracy: 0.8522 - val_loss: 0.4671 - val_accuracy: 0.8341\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.4313 - accuracy: 0.8522 - val_loss: 0.4666 - val_accuracy: 0.8342\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 2s 42us/sample - loss: 0.4296 - accuracy: 0.8527 - val_loss: 0.4660 - val_accuracy: 0.8343\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.4309 - accuracy: 0.8515 - val_loss: 0.4660 - val_accuracy: 0.8339\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4300 - accuracy: 0.8520 - val_loss: 0.4657 - val_accuracy: 0.8340\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.4308 - accuracy: 0.8527 - val_loss: 0.4655 - val_accuracy: 0.8345\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.4303 - accuracy: 0.8532 - val_loss: 0.4649 - val_accuracy: 0.8352\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.4283 - accuracy: 0.8527 - val_loss: 0.4646 - val_accuracy: 0.8346\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.4284 - accuracy: 0.8538 - val_loss: 0.4648 - val_accuracy: 0.8347\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.4279 - accuracy: 0.8533 - val_loss: 0.4642 - val_accuracy: 0.8355\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.4288 - accuracy: 0.8528 - val_loss: 0.4637 - val_accuracy: 0.8357\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.4272 - accuracy: 0.8526 - val_loss: 0.4638 - val_accuracy: 0.8363\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.4264 - accuracy: 0.8543 - val_loss: 0.4629 - val_accuracy: 0.8358\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.4269 - accuracy: 0.8541 - val_loss: 0.4633 - val_accuracy: 0.8353\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.4254 - accuracy: 0.8532 - val_loss: 0.4628 - val_accuracy: 0.8359\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.4244 - accuracy: 0.8551 - val_loss: 0.4625 - val_accuracy: 0.8361\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4253 - accuracy: 0.8542 - val_loss: 0.4625 - val_accuracy: 0.8356\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.4248 - accuracy: 0.8542 - val_loss: 0.4622 - val_accuracy: 0.8359\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.4241 - accuracy: 0.8548 - val_loss: 0.4624 - val_accuracy: 0.8367\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 44us/sample - loss: 0.4239 - accuracy: 0.8549 - val_loss: 0.4619 - val_accuracy: 0.8371\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.4243 - accuracy: 0.8539 - val_loss: 0.4617 - val_accuracy: 0.8372\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.4238 - accuracy: 0.8544 - val_loss: 0.4613 - val_accuracy: 0.8357\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.4234 - accuracy: 0.8552 - val_loss: 0.4613 - val_accuracy: 0.8370\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.4234 - accuracy: 0.8551 - val_loss: 0.4612 - val_accuracy: 0.8366\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.4226 - accuracy: 0.8536 - val_loss: 0.4607 - val_accuracy: 0.8377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ff8140c3c8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(trainX,trainY,          \n",
    "          validation_data=(testX,testY),\n",
    "          epochs=100,\n",
    "          batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CSqKvpOIVk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGAad54JOIVm"
   },
   "outputs": [],
   "source": [
    "#Initialize Sequential model\n",
    "model4 = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model4.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Normalize the data\n",
    "model4.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ7oIymROIVp"
   },
   "outputs": [],
   "source": [
    "#Add 1st hidden layer\n",
    "model4.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "\n",
    "#Add 2nd hidden layer\n",
    "model4.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "\n",
    "#Add OUTPUT layer\n",
    "model4.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-O-fFxnOIVt"
   },
   "outputs": [],
   "source": [
    "sgd_optimizer2 = tf.keras.optimizers.SGD(lr=0.03)\n",
    "\n",
    "#Compile the model\n",
    "model4.compile(optimizer=sgd_optimizer2, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiP7IL52OIVw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 1.5432 - accuracy: 0.6073 - val_loss: 1.0228 - val_accuracy: 0.7248\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.8441 - accuracy: 0.7361 - val_loss: 0.7330 - val_accuracy: 0.7495\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.6735 - accuracy: 0.7655 - val_loss: 0.6346 - val_accuracy: 0.7753\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.5960 - accuracy: 0.7902 - val_loss: 0.5777 - val_accuracy: 0.7945\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.5467 - accuracy: 0.8077 - val_loss: 0.5403 - val_accuracy: 0.8079\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.5124 - accuracy: 0.8195 - val_loss: 0.5130 - val_accuracy: 0.8176\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.4876 - accuracy: 0.8266 - val_loss: 0.4926 - val_accuracy: 0.8263\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.4674 - accuracy: 0.8340 - val_loss: 0.4784 - val_accuracy: 0.8278\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4529 - accuracy: 0.8388 - val_loss: 0.4663 - val_accuracy: 0.8315\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.4405 - accuracy: 0.8445 - val_loss: 0.4561 - val_accuracy: 0.8387\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4300 - accuracy: 0.8470 - val_loss: 0.4499 - val_accuracy: 0.8387\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4210 - accuracy: 0.8508 - val_loss: 0.4413 - val_accuracy: 0.8405\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.4128 - accuracy: 0.8530 - val_loss: 0.4350 - val_accuracy: 0.8422\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.4057 - accuracy: 0.8563 - val_loss: 0.4285 - val_accuracy: 0.8428\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.3996 - accuracy: 0.8580 - val_loss: 0.4243 - val_accuracy: 0.8464\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.3933 - accuracy: 0.8606 - val_loss: 0.4202 - val_accuracy: 0.8484\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3870 - accuracy: 0.8635 - val_loss: 0.4150 - val_accuracy: 0.8502\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3820 - accuracy: 0.8645 - val_loss: 0.4113 - val_accuracy: 0.8518\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3776 - accuracy: 0.8658 - val_loss: 0.4071 - val_accuracy: 0.8533\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.3717 - accuracy: 0.8676 - val_loss: 0.4048 - val_accuracy: 0.8554\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.3691 - accuracy: 0.8698 - val_loss: 0.3999 - val_accuracy: 0.8576\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3641 - accuracy: 0.8709 - val_loss: 0.3958 - val_accuracy: 0.8583\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3598 - accuracy: 0.8721 - val_loss: 0.3931 - val_accuracy: 0.8597\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.3554 - accuracy: 0.8741 - val_loss: 0.3919 - val_accuracy: 0.8610\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3528 - accuracy: 0.8746 - val_loss: 0.3875 - val_accuracy: 0.8621\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3481 - accuracy: 0.8766 - val_loss: 0.3868 - val_accuracy: 0.8628\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3448 - accuracy: 0.8782 - val_loss: 0.3821 - val_accuracy: 0.8647\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.3421 - accuracy: 0.8799 - val_loss: 0.3803 - val_accuracy: 0.8656\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3385 - accuracy: 0.8805 - val_loss: 0.3788 - val_accuracy: 0.8642\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.3347 - accuracy: 0.8811 - val_loss: 0.3758 - val_accuracy: 0.8648\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 7s 110us/sample - loss: 0.3323 - accuracy: 0.8824 - val_loss: 0.3732 - val_accuracy: 0.8680\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3282 - accuracy: 0.8839 - val_loss: 0.3709 - val_accuracy: 0.8681\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3263 - accuracy: 0.8846 - val_loss: 0.3694 - val_accuracy: 0.8685\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.3223 - accuracy: 0.8859 - val_loss: 0.3673 - val_accuracy: 0.8684\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3214 - accuracy: 0.8853 - val_loss: 0.3653 - val_accuracy: 0.8714\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3172 - accuracy: 0.8877 - val_loss: 0.3646 - val_accuracy: 0.8690\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3157 - accuracy: 0.8876 - val_loss: 0.3623 - val_accuracy: 0.8716\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3125 - accuracy: 0.8892 - val_loss: 0.3617 - val_accuracy: 0.8700\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.3101 - accuracy: 0.8895 - val_loss: 0.3598 - val_accuracy: 0.8714\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.3087 - accuracy: 0.8901 - val_loss: 0.3587 - val_accuracy: 0.8710\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.3055 - accuracy: 0.8915 - val_loss: 0.3561 - val_accuracy: 0.8733\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.3029 - accuracy: 0.8926 - val_loss: 0.3579 - val_accuracy: 0.8728\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.3010 - accuracy: 0.8927 - val_loss: 0.3560 - val_accuracy: 0.8742\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2994 - accuracy: 0.8934 - val_loss: 0.3537 - val_accuracy: 0.8750\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2959 - accuracy: 0.8945 - val_loss: 0.3510 - val_accuracy: 0.8746\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2936 - accuracy: 0.8954 - val_loss: 0.3508 - val_accuracy: 0.8756\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2909 - accuracy: 0.8967 - val_loss: 0.3491 - val_accuracy: 0.8748\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2893 - accuracy: 0.8974 - val_loss: 0.3478 - val_accuracy: 0.8741\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.2864 - accuracy: 0.8987 - val_loss: 0.3479 - val_accuracy: 0.8759\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2842 - accuracy: 0.8983 - val_loss: 0.3461 - val_accuracy: 0.8758\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2832 - accuracy: 0.8991 - val_loss: 0.3465 - val_accuracy: 0.8759\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2798 - accuracy: 0.8999 - val_loss: 0.3460 - val_accuracy: 0.8759\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2771 - accuracy: 0.9015 - val_loss: 0.3431 - val_accuracy: 0.8781\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2762 - accuracy: 0.9016 - val_loss: 0.3430 - val_accuracy: 0.8775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 8s 135us/sample - loss: 0.2741 - accuracy: 0.9017 - val_loss: 0.3416 - val_accuracy: 0.8782\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 8s 130us/sample - loss: 0.2717 - accuracy: 0.9035 - val_loss: 0.3408 - val_accuracy: 0.8776\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.2702 - accuracy: 0.9028 - val_loss: 0.3400 - val_accuracy: 0.8772\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.2683 - accuracy: 0.9053 - val_loss: 0.3394 - val_accuracy: 0.8778\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.2655 - accuracy: 0.9055 - val_loss: 0.3395 - val_accuracy: 0.8778\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.2641 - accuracy: 0.9057 - val_loss: 0.3387 - val_accuracy: 0.8798\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.2633 - accuracy: 0.9072 - val_loss: 0.3366 - val_accuracy: 0.8794\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2614 - accuracy: 0.9069 - val_loss: 0.3372 - val_accuracy: 0.8793\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2584 - accuracy: 0.9086 - val_loss: 0.3354 - val_accuracy: 0.8795\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2564 - accuracy: 0.9082 - val_loss: 0.3355 - val_accuracy: 0.8808\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.2540 - accuracy: 0.9101 - val_loss: 0.3350 - val_accuracy: 0.8810\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2539 - accuracy: 0.9099 - val_loss: 0.3341 - val_accuracy: 0.8805\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.2507 - accuracy: 0.9110 - val_loss: 0.3334 - val_accuracy: 0.8802\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2489 - accuracy: 0.9110 - val_loss: 0.3333 - val_accuracy: 0.8810\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2467 - accuracy: 0.9123 - val_loss: 0.3353 - val_accuracy: 0.8822\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.2466 - accuracy: 0.9113 - val_loss: 0.3341 - val_accuracy: 0.8816\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2425 - accuracy: 0.9134 - val_loss: 0.3331 - val_accuracy: 0.8803\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.2405 - accuracy: 0.9139 - val_loss: 0.3317 - val_accuracy: 0.8814\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2402 - accuracy: 0.9143 - val_loss: 0.3335 - val_accuracy: 0.8804\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.2375 - accuracy: 0.9161 - val_loss: 0.3322 - val_accuracy: 0.8812\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 8s 128us/sample - loss: 0.2362 - accuracy: 0.9159 - val_loss: 0.3381 - val_accuracy: 0.8805\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 9s 150us/sample - loss: 0.2364 - accuracy: 0.9159 - val_loss: 0.3301 - val_accuracy: 0.8841\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 11s 188us/sample - loss: 0.2331 - accuracy: 0.9167 - val_loss: 0.3305 - val_accuracy: 0.8833\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2319 - accuracy: 0.9181 - val_loss: 0.3303 - val_accuracy: 0.8837\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.2294 - accuracy: 0.9192 - val_loss: 0.3295 - val_accuracy: 0.8813\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2277 - accuracy: 0.9192 - val_loss: 0.3304 - val_accuracy: 0.8831\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2265 - accuracy: 0.9193 - val_loss: 0.3302 - val_accuracy: 0.8816\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2254 - accuracy: 0.9197 - val_loss: 0.3285 - val_accuracy: 0.8829\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2226 - accuracy: 0.9209 - val_loss: 0.3292 - val_accuracy: 0.8827\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2219 - accuracy: 0.9213 - val_loss: 0.3297 - val_accuracy: 0.8838\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.2194 - accuracy: 0.9222 - val_loss: 0.3285 - val_accuracy: 0.8843\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2186 - accuracy: 0.9220 - val_loss: 0.3285 - val_accuracy: 0.8827\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 7s 113us/sample - loss: 0.2162 - accuracy: 0.9236 - val_loss: 0.3279 - val_accuracy: 0.8837\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.2147 - accuracy: 0.9238 - val_loss: 0.3286 - val_accuracy: 0.8849\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2141 - accuracy: 0.9247 - val_loss: 0.3280 - val_accuracy: 0.8825\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.2109 - accuracy: 0.9255 - val_loss: 0.3278 - val_accuracy: 0.8844\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 10s 175us/sample - loss: 0.2098 - accuracy: 0.9259 - val_loss: 0.3276 - val_accuracy: 0.8834\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2079 - accuracy: 0.9266 - val_loss: 0.3275 - val_accuracy: 0.8850\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.2069 - accuracy: 0.9275 - val_loss: 0.3292 - val_accuracy: 0.8833\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.2058 - accuracy: 0.9264 - val_loss: 0.3284 - val_accuracy: 0.8849\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.2043 - accuracy: 0.9277 - val_loss: 0.3320 - val_accuracy: 0.8841\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2021 - accuracy: 0.9288 - val_loss: 0.3288 - val_accuracy: 0.8851\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2005 - accuracy: 0.9293 - val_loss: 0.3301 - val_accuracy: 0.8843\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.1991 - accuracy: 0.9294 - val_loss: 0.3295 - val_accuracy: 0.8847\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.1981 - accuracy: 0.9305 - val_loss: 0.3296 - val_accuracy: 0.8861\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1958 - accuracy: 0.9316 - val_loss: 0.3312 - val_accuracy: 0.8852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ff81decef0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(trainX,trainY,          \n",
    "          validation_data=(testX,testY),\n",
    "          epochs=100,\n",
    "          batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2YsZV0OIV0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4ojW6-oOIV2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_6 (Reshape)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 92,746\n",
      "Trainable params: 91,178\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfFGmbZLOIV5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bIkbMEN5OIV7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "R6_ExternalLab_AIML.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
