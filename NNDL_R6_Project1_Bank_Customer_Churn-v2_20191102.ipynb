{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNDL - Project 1: Bank Customer Churn Prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The case study is from an open source dataset from Kaggle. \n",
    "\n",
    "Link to the Kaggle project site:\n",
    "https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling\n",
    " \n",
    "Given a Bank customer, can we build a classifier which can determine whether they will leave or not using Neural networks?\n",
    " \n",
    "Case file: bank.csv\n",
    "\n",
    "The points distribution for this case is as follows:\n",
    "1. Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "bank_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Drop the columns which are unique for all users like IDs (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = bank_df.drop(columns=['RowNumber','CustomerId','Surname'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "France     5014\n",
       "Germany    2509\n",
       "Spain      2477\n",
       "Name: Geography, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Geography'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      5457\n",
       "Female    4543\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Exited'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical boolean mask\n",
    "categorical_feature_mask = df.dtypes==object\n",
    "# filter categorical columns using mask and turn it into a list\n",
    "categorical_cols = df.columns[categorical_feature_mask].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# instantiate labelencoder object\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Geography  Gender\n",
       "0          0       0\n",
       "1          2       0\n",
       "2          0       0\n",
       "3          0       0\n",
       "4          2       0\n",
       "5          2       1\n",
       "6          0       1\n",
       "7          1       0\n",
       "8          0       1\n",
       "9          0       1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply le on categorical feature columns\n",
    "df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "df[categorical_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619          0       0   42       2       0.00              1   \n",
       "1          608          2       0   41       1   83807.86              1   \n",
       "2          502          0       0   42       8  159660.80              3   \n",
       "3          699          0       0   39       1       0.00              2   \n",
       "4          850          2       0   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Distinguish the feature and target set (2.5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Exited']\n",
    "X = df.drop(columns ='Exited')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. ... 1. 1. 0.]\n",
      "[[6.1900000e+02 0.0000000e+00 0.0000000e+00 ... 1.0000000e+00\n",
      "  1.0000000e+00 1.0134888e+05]\n",
      " [6.0800000e+02 2.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  1.0000000e+00 1.1254258e+05]\n",
      " [5.0200000e+02 0.0000000e+00 0.0000000e+00 ... 1.0000000e+00\n",
      "  0.0000000e+00 1.1393157e+05]\n",
      " ...\n",
      " [7.0900000e+02 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  1.0000000e+00 4.2085578e+04]\n",
      " [7.7200000e+02 1.0000000e+00 1.0000000e+00 ... 1.0000000e+00\n",
      "  0.0000000e+00 9.2888523e+04]\n",
      " [7.9200000e+02 0.0000000e+00 0.0000000e+00 ... 1.0000000e+00\n",
      "  0.0000000e+00 3.8190781e+04]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(y).astype('float32')\n",
    "features = np.array(X).astype('float32')\n",
    "print(labels)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Divide the data set into Train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from scipy.stats import zscore\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.25, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Normalize the train and test data (2.5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_z = tf.math.l2_normalize(X_train) \n",
    "X_test_z  = tf.math.l2_normalize(X_test)\n",
    "X_train_z.shape\n",
    "X_train_norm = stats.zscore(X_train)\n",
    "X_test_norm = stats.zscore(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY = tf.keras.utils.to_categorical(y_train)\n",
    "testY = tf.keras.utils.to_categorical(y_test)\n",
    "#trainY = tf.convert_to_tensor(y_train)\n",
    "#testY = tf.convert_to_tensor(y_test)\n",
    "print(trainY)\n",
    "testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Initialize & build the model (7.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "#Initialize Sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Input Layer\n",
    "model.add(tf.keras.layers.Dense(10, input_dim = 10, activation='relu'))\n",
    "\n",
    "#Add OUTPUT layer\n",
    "model.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
    "\n",
    "#Compile the model\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/30\n",
      "7500/7500 [==============================] - 2s 247us/sample - loss: 0.3939 - accuracy: 0.8383 - val_loss: 0.3925 - val_accuracy: 0.8414\n",
      "Epoch 2/30\n",
      "7500/7500 [==============================] - 2s 233us/sample - loss: 0.3879 - accuracy: 0.8420 - val_loss: 0.3856 - val_accuracy: 0.8438\n",
      "Epoch 3/30\n",
      "7500/7500 [==============================] - 2s 232us/sample - loss: 0.3820 - accuracy: 0.8461 - val_loss: 0.3793 - val_accuracy: 0.8470\n",
      "Epoch 4/30\n",
      "7500/7500 [==============================] - 2s 223us/sample - loss: 0.3765 - accuracy: 0.8497 - val_loss: 0.3733 - val_accuracy: 0.8488\n",
      "Epoch 5/30\n",
      "7500/7500 [==============================] - 2s 239us/sample - loss: 0.3718 - accuracy: 0.8512 - val_loss: 0.3682 - val_accuracy: 0.8506\n",
      "Epoch 6/30\n",
      "7500/7500 [==============================] - 2s 236us/sample - loss: 0.3679 - accuracy: 0.8532 - val_loss: 0.3636 - val_accuracy: 0.8508\n",
      "Epoch 7/30\n",
      "7500/7500 [==============================] - 2s 233us/sample - loss: 0.3645 - accuracy: 0.8547 - val_loss: 0.3602 - val_accuracy: 0.8516\n",
      "Epoch 8/30\n",
      "7500/7500 [==============================] - 2s 234us/sample - loss: 0.3616 - accuracy: 0.8559 - val_loss: 0.3578 - val_accuracy: 0.8528\n",
      "Epoch 9/30\n",
      "7500/7500 [==============================] - 2s 235us/sample - loss: 0.3592 - accuracy: 0.8569 - val_loss: 0.3552 - val_accuracy: 0.8548\n",
      "Epoch 10/30\n",
      "7500/7500 [==============================] - 2s 268us/sample - loss: 0.3576 - accuracy: 0.8580 - val_loss: 0.3536 - val_accuracy: 0.8538\n",
      "Epoch 11/30\n",
      "7500/7500 [==============================] - 2s 259us/sample - loss: 0.3562 - accuracy: 0.8580 - val_loss: 0.3521 - val_accuracy: 0.8544\n",
      "Epoch 12/30\n",
      "7500/7500 [==============================] - 2s 251us/sample - loss: 0.3551 - accuracy: 0.8577 - val_loss: 0.3509 - val_accuracy: 0.8568\n",
      "Epoch 13/30\n",
      "7500/7500 [==============================] - 2s 268us/sample - loss: 0.3542 - accuracy: 0.8573 - val_loss: 0.3504 - val_accuracy: 0.8570\n",
      "Epoch 14/30\n",
      "7500/7500 [==============================] - 2s 298us/sample - loss: 0.3533 - accuracy: 0.8574 - val_loss: 0.3491 - val_accuracy: 0.8570\n",
      "Epoch 15/30\n",
      "7500/7500 [==============================] - 2s 250us/sample - loss: 0.3528 - accuracy: 0.8576 - val_loss: 0.3487 - val_accuracy: 0.8560\n",
      "Epoch 16/30\n",
      "7500/7500 [==============================] - 2s 260us/sample - loss: 0.3522 - accuracy: 0.8559 - val_loss: 0.3479 - val_accuracy: 0.8560\n",
      "Epoch 17/30\n",
      "7500/7500 [==============================] - 2s 254us/sample - loss: 0.3517 - accuracy: 0.8577 - val_loss: 0.3474 - val_accuracy: 0.8528\n",
      "Epoch 18/30\n",
      "7500/7500 [==============================] - 2s 270us/sample - loss: 0.3516 - accuracy: 0.8583 - val_loss: 0.3469 - val_accuracy: 0.8562\n",
      "Epoch 19/30\n",
      "7500/7500 [==============================] - 2s 260us/sample - loss: 0.3510 - accuracy: 0.8570 - val_loss: 0.3478 - val_accuracy: 0.8572\n",
      "Epoch 20/30\n",
      "7500/7500 [==============================] - 2s 280us/sample - loss: 0.3511 - accuracy: 0.8591 - val_loss: 0.3463 - val_accuracy: 0.8564\n",
      "Epoch 21/30\n",
      "7500/7500 [==============================] - 2s 255us/sample - loss: 0.3507 - accuracy: 0.8591 - val_loss: 0.3464 - val_accuracy: 0.8576\n",
      "Epoch 22/30\n",
      "7500/7500 [==============================] - 2s 269us/sample - loss: 0.3506 - accuracy: 0.8574 - val_loss: 0.3463 - val_accuracy: 0.8566\n",
      "Epoch 23/30\n",
      "7500/7500 [==============================] - 2s 239us/sample - loss: 0.3505 - accuracy: 0.8589 - val_loss: 0.3456 - val_accuracy: 0.8562\n",
      "Epoch 24/30\n",
      "7500/7500 [==============================] - 2s 215us/sample - loss: 0.3500 - accuracy: 0.8594 - val_loss: 0.3464 - val_accuracy: 0.8582\n",
      "Epoch 25/30\n",
      "7500/7500 [==============================] - 2s 227us/sample - loss: 0.3503 - accuracy: 0.8577 - val_loss: 0.3457 - val_accuracy: 0.8568\n",
      "Epoch 26/30\n",
      "7500/7500 [==============================] - 2s 241us/sample - loss: 0.3499 - accuracy: 0.8589 - val_loss: 0.3461 - val_accuracy: 0.8536\n",
      "Epoch 27/30\n",
      "7500/7500 [==============================] - 2s 233us/sample - loss: 0.3501 - accuracy: 0.8588 - val_loss: 0.3455 - val_accuracy: 0.8572\n",
      "Epoch 28/30\n",
      "7500/7500 [==============================] - 2s 228us/sample - loss: 0.3498 - accuracy: 0.8591 - val_loss: 0.3445 - val_accuracy: 0.8558\n",
      "Epoch 29/30\n",
      "7500/7500 [==============================] - 2s 236us/sample - loss: 0.3499 - accuracy: 0.8590 - val_loss: 0.3448 - val_accuracy: 0.8560\n",
      "Epoch 30/30\n",
      "7500/7500 [==============================] - 2s 215us/sample - loss: 0.3498 - accuracy: 0.8573 - val_loss: 0.3447 - val_accuracy: 0.8566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23fb0e0d7f0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_norm,trainY,          \n",
    "          validation_data=(X_test_norm,testY),\n",
    "          epochs=30,\n",
    "          batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 132\n",
      "Trainable params: 132\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Optimize the model (5 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Nadam\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers import Dropout\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first findout the best optimizer among 'SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam'):\n",
    "    #Initialize Sequential model\n",
    "    model2 = Sequential()\n",
    "  \n",
    "    #Input Layer\n",
    "    model2.add(Dense(10, input_dim = 10, activation='relu'))\n",
    "  \n",
    "    #Add 2nd Hidden layer\n",
    "    model2.add(Dense(6, activation='relu'))\n",
    "\n",
    "    #Add Dense Layer which provides 1 Outputs after applying softmax (Output Layer)\n",
    "    model2.add(Dense(1, activation='sigmoid'))\n",
    "  \n",
    "\n",
    "    \n",
    "    #Comile the model\n",
    "    model2.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  \n",
    "    return model2\n",
    "\n",
    "model2 = KerasClassifier(build_fn=create_model, epochs=50, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.856667 using {'optimizer': 'SGD'}\n",
      "0.856667 (0.001467) with: {'optimizer': 'SGD'}\n",
      "0.853067 (0.004000) with: {'optimizer': 'RMSprop'}\n",
      "0.832933 (0.011333) with: {'optimizer': 'Adagrad'}\n",
      "0.855333 (0.000400) with: {'optimizer': 'Adadelta'}\n",
      "0.853467 (0.001733) with: {'optimizer': 'Adam'}\n",
      "0.854133 (0.001067) with: {'optimizer': 'Adamax'}\n",
      "0.851067 (0.001733) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "\n",
    "grid = GridSearchCV(estimator=model2, param_grid=param_grid, n_jobs=-1, scoring=\"accuracy\", cv=2)\n",
    "grid_result = grid.fit(X_train_norm,y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "                       print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations:\n",
    "\n",
    "The best optimizer we have got is Nadam and the accuracy is 85.67%.\n",
    "\n",
    "There is no discernable increase in accuracy of the model.\n",
    "\n",
    "Note: As there is difference in multiclass representation with scikit-learn and keras, we are not going to use the categorical transformation on target variable with gridsearch. If we use the categorical transformation of target variable, we will be ending up with the error, *\"ValueError: Classification metrics can't handle a mix of multilabel-indicator and binary targets\"*. So with gridsearchcv, we are going to use target variable without categorical transformation.\n",
    "\n",
    "Let's find the best learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Learning Rate\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(learn_rate=0.01):\n",
    "    #Initialize Sequential model\n",
    "    model4 = Sequential()\n",
    "    #Input Layer\n",
    "    model4.add(Dense(10, input_dim = 10, activation='relu'))\n",
    "    #Add 2nd Hidden layer\n",
    "    model4.add(Dense(6, activation='relu'))\n",
    "    #Add Dense Layer which provides 1 Outputs after applying sigmoid (Output Layer)\n",
    "    model4.add(Dense(2, activation='sigmoid'))\n",
    "    #Comile the model\n",
    "    optimizer = SGD(lr=learn_rate)\n",
    "    model4.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model4\n",
    "\n",
    "# create model\n",
    "model4 = KerasClassifier(build_fn=create_model, epochs=50, batch_size=20, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.854733 using {'learn_rate': 0.2}\n",
      "0.797867 (0.001467) with: {'learn_rate': 0.001}\n",
      "0.834133 (0.016400) with: {'learn_rate': 0.01}\n",
      "0.853667 (0.003133) with: {'learn_rate': 0.1}\n",
      "0.854733 (0.000333) with: {'learn_rate': 0.2}\n",
      "0.851200 (0.003467) with: {'learn_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "param_grid = dict(learn_rate=learn_rate)\n",
    "\n",
    "grid2 = GridSearchCV(estimator=model4, param_grid=param_grid, n_jobs=1, cv=2)\n",
    "grid_result2 = grid2.fit(X_train_norm, trainY)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result2.best_score_, grid_result2.best_params_))\n",
    "means = grid_result2.cv_results_['mean_test_score']\n",
    "stds = grid_result2.cv_results_['std_test_score']\n",
    "params = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "#### The best learning rate we got is 0.2 and the accuracy is 85.4733%.\n",
    "#### There is a slight decrease in accuracy.\n",
    "\n",
    "Lets put together the final model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/50\n",
      "7500/7500 [==============================] - 2s 323us/sample - loss: 0.5588 - accuracy: 0.7419 - val_loss: 0.4903 - val_accuracy: 0.7924\n",
      "Epoch 2/50\n",
      "7500/7500 [==============================] - 2s 228us/sample - loss: 0.4728 - accuracy: 0.7960 - val_loss: 0.4653 - val_accuracy: 0.7966\n",
      "Epoch 3/50\n",
      "7500/7500 [==============================] - 2s 223us/sample - loss: 0.4560 - accuracy: 0.7986 - val_loss: 0.4524 - val_accuracy: 0.7996\n",
      "Epoch 4/50\n",
      "7500/7500 [==============================] - 2s 222us/sample - loss: 0.4469 - accuracy: 0.7997 - val_loss: 0.4443 - val_accuracy: 0.8016\n",
      "Epoch 5/50\n",
      "7500/7500 [==============================] - 2s 223us/sample - loss: 0.4409 - accuracy: 0.8017 - val_loss: 0.4385 - val_accuracy: 0.8040\n",
      "Epoch 6/50\n",
      "7500/7500 [==============================] - 2s 230us/sample - loss: 0.4364 - accuracy: 0.8043 - val_loss: 0.4333 - val_accuracy: 0.8054\n",
      "Epoch 7/50\n",
      "7500/7500 [==============================] - 2s 223us/sample - loss: 0.4324 - accuracy: 0.8069 - val_loss: 0.4292 - val_accuracy: 0.8094\n",
      "Epoch 8/50\n",
      "7500/7500 [==============================] - 2s 218us/sample - loss: 0.4285 - accuracy: 0.8113 - val_loss: 0.4252 - val_accuracy: 0.8150\n",
      "Epoch 9/50\n",
      "7500/7500 [==============================] - 2s 223us/sample - loss: 0.4245 - accuracy: 0.8128 - val_loss: 0.4208 - val_accuracy: 0.8192\n",
      "Epoch 10/50\n",
      "7500/7500 [==============================] - 2s 241us/sample - loss: 0.4198 - accuracy: 0.8165 - val_loss: 0.4158 - val_accuracy: 0.8228\n",
      "Epoch 11/50\n",
      "7500/7500 [==============================] - 2s 234us/sample - loss: 0.4145 - accuracy: 0.8206 - val_loss: 0.4104 - val_accuracy: 0.8286\n",
      "Epoch 12/50\n",
      "7500/7500 [==============================] - 2s 238us/sample - loss: 0.4089 - accuracy: 0.8245 - val_loss: 0.4044 - val_accuracy: 0.8342\n",
      "Epoch 13/50\n",
      "7500/7500 [==============================] - 2s 234us/sample - loss: 0.4032 - accuracy: 0.8304 - val_loss: 0.3986 - val_accuracy: 0.8378\n",
      "Epoch 14/50\n",
      "7500/7500 [==============================] - 2s 233us/sample - loss: 0.3974 - accuracy: 0.8349 - val_loss: 0.3927 - val_accuracy: 0.8418\n",
      "Epoch 15/50\n",
      "7500/7500 [==============================] - 2s 237us/sample - loss: 0.3919 - accuracy: 0.8377 - val_loss: 0.3871 - val_accuracy: 0.8452\n",
      "Epoch 16/50\n",
      "7500/7500 [==============================] - 2s 253us/sample - loss: 0.3865 - accuracy: 0.8408 - val_loss: 0.3817 - val_accuracy: 0.8488\n",
      "Epoch 17/50\n",
      "7500/7500 [==============================] - 2s 232us/sample - loss: 0.3813 - accuracy: 0.8439 - val_loss: 0.3764 - val_accuracy: 0.8482\n",
      "Epoch 18/50\n",
      "7500/7500 [==============================] - 2s 235us/sample - loss: 0.3768 - accuracy: 0.8461 - val_loss: 0.3721 - val_accuracy: 0.8500\n",
      "Epoch 19/50\n",
      "7500/7500 [==============================] - 2s 237us/sample - loss: 0.3725 - accuracy: 0.8493 - val_loss: 0.3686 - val_accuracy: 0.8518\n",
      "Epoch 20/50\n",
      "7500/7500 [==============================] - 2s 239us/sample - loss: 0.3691 - accuracy: 0.8505 - val_loss: 0.3648 - val_accuracy: 0.8544\n",
      "Epoch 21/50\n",
      "7500/7500 [==============================] - 2s 230us/sample - loss: 0.3661 - accuracy: 0.8518 - val_loss: 0.3625 - val_accuracy: 0.8548\n",
      "Epoch 22/50\n",
      "7500/7500 [==============================] - 2s 232us/sample - loss: 0.3637 - accuracy: 0.8525 - val_loss: 0.3601 - val_accuracy: 0.8546\n",
      "Epoch 23/50\n",
      "7500/7500 [==============================] - 2s 238us/sample - loss: 0.3616 - accuracy: 0.8539 - val_loss: 0.3582 - val_accuracy: 0.8566\n",
      "Epoch 24/50\n",
      "7500/7500 [==============================] - 2s 228us/sample - loss: 0.3598 - accuracy: 0.8538 - val_loss: 0.3565 - val_accuracy: 0.8568\n",
      "Epoch 25/50\n",
      "7500/7500 [==============================] - 2s 232us/sample - loss: 0.3583 - accuracy: 0.8549 - val_loss: 0.3548 - val_accuracy: 0.8568\n",
      "Epoch 26/50\n",
      "7500/7500 [==============================] - 2s 236us/sample - loss: 0.3569 - accuracy: 0.8555 - val_loss: 0.3539 - val_accuracy: 0.8560\n",
      "Epoch 27/50\n",
      "7500/7500 [==============================] - 2s 232us/sample - loss: 0.3559 - accuracy: 0.8548 - val_loss: 0.3526 - val_accuracy: 0.8580\n",
      "Epoch 28/50\n",
      "7500/7500 [==============================] - 2s 250us/sample - loss: 0.3549 - accuracy: 0.8561 - val_loss: 0.3508 - val_accuracy: 0.8594\n",
      "Epoch 29/50\n",
      "7500/7500 [==============================] - 2s 248us/sample - loss: 0.3541 - accuracy: 0.8554 - val_loss: 0.3501 - val_accuracy: 0.8592\n",
      "Epoch 30/50\n",
      "7500/7500 [==============================] - 2s 237us/sample - loss: 0.3533 - accuracy: 0.8556 - val_loss: 0.3491 - val_accuracy: 0.8608\n",
      "Epoch 31/50\n",
      "7500/7500 [==============================] - 2s 237us/sample - loss: 0.3525 - accuracy: 0.8564 - val_loss: 0.3485 - val_accuracy: 0.8572\n",
      "Epoch 32/50\n",
      "7500/7500 [==============================] - 2s 224us/sample - loss: 0.3519 - accuracy: 0.8565 - val_loss: 0.3477 - val_accuracy: 0.8584\n",
      "Epoch 33/50\n",
      "7500/7500 [==============================] - 2s 249us/sample - loss: 0.3514 - accuracy: 0.8561 - val_loss: 0.3467 - val_accuracy: 0.8588\n",
      "Epoch 34/50\n",
      "7500/7500 [==============================] - 2s 239us/sample - loss: 0.3512 - accuracy: 0.8564 - val_loss: 0.3469 - val_accuracy: 0.8584\n",
      "Epoch 35/50\n",
      "7500/7500 [==============================] - 2s 240us/sample - loss: 0.3502 - accuracy: 0.8549 - val_loss: 0.3475 - val_accuracy: 0.8628\n",
      "Epoch 36/50\n",
      "7500/7500 [==============================] - 2s 226us/sample - loss: 0.3504 - accuracy: 0.8567 - val_loss: 0.3459 - val_accuracy: 0.8584\n",
      "Epoch 37/50\n",
      "7500/7500 [==============================] - 2s 226us/sample - loss: 0.3501 - accuracy: 0.8557 - val_loss: 0.3451 - val_accuracy: 0.8596\n",
      "Epoch 38/50\n",
      "7500/7500 [==============================] - 2s 224us/sample - loss: 0.3499 - accuracy: 0.8562 - val_loss: 0.3444 - val_accuracy: 0.8600\n",
      "Epoch 39/50\n",
      "7500/7500 [==============================] - 2s 216us/sample - loss: 0.3494 - accuracy: 0.8550 - val_loss: 0.3451 - val_accuracy: 0.8624\n",
      "Epoch 40/50\n",
      "7500/7500 [==============================] - 2s 225us/sample - loss: 0.3493 - accuracy: 0.8560 - val_loss: 0.3450 - val_accuracy: 0.8614\n",
      "Epoch 41/50\n",
      "7500/7500 [==============================] - 2s 218us/sample - loss: 0.3493 - accuracy: 0.8569 - val_loss: 0.3438 - val_accuracy: 0.8626\n",
      "Epoch 42/50\n",
      "7500/7500 [==============================] - 2s 236us/sample - loss: 0.3490 - accuracy: 0.8564 - val_loss: 0.3433 - val_accuracy: 0.8600\n",
      "Epoch 43/50\n",
      "7500/7500 [==============================] - 2s 221us/sample - loss: 0.3489 - accuracy: 0.8569 - val_loss: 0.3433 - val_accuracy: 0.8630\n",
      "Epoch 44/50\n",
      "7500/7500 [==============================] - 2s 220us/sample - loss: 0.3485 - accuracy: 0.8555 - val_loss: 0.3440 - val_accuracy: 0.8638\n",
      "Epoch 45/50\n",
      "7500/7500 [==============================] - 2s 221us/sample - loss: 0.3486 - accuracy: 0.8571 - val_loss: 0.3435 - val_accuracy: 0.8608\n",
      "Epoch 46/50\n",
      "7500/7500 [==============================] - 2s 223us/sample - loss: 0.3484 - accuracy: 0.8561 - val_loss: 0.3423 - val_accuracy: 0.8626\n",
      "Epoch 47/50\n",
      "7500/7500 [==============================] - 2s 226us/sample - loss: 0.3483 - accuracy: 0.8570 - val_loss: 0.3423 - val_accuracy: 0.8636\n",
      "Epoch 48/50\n",
      "7500/7500 [==============================] - 2s 217us/sample - loss: 0.3481 - accuracy: 0.8570 - val_loss: 0.3427 - val_accuracy: 0.8632\n",
      "Epoch 49/50\n",
      "7500/7500 [==============================] - 2s 218us/sample - loss: 0.3481 - accuracy: 0.8569 - val_loss: 0.3423 - val_accuracy: 0.8638\n",
      "Epoch 50/50\n",
      "7500/7500 [==============================] - 2s 221us/sample - loss: 0.3478 - accuracy: 0.8577 - val_loss: 0.3419 - val_accuracy: 0.8614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23fbb4ad400>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize Sequential model\n",
    "modelF = tf.keras.models.Sequential()\n",
    "\n",
    "#Input Layer\n",
    "modelF.add(tf.keras.layers.Dense(10, input_dim = 10, activation='relu'))\n",
    "\n",
    "#Add OUTPUT layer\n",
    "modelF.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
    "\n",
    "#Compile the model\n",
    "modelF.compile(optimizer='sgd', loss='binary_crossentropy',metrics=['accuracy'])\n",
    " \n",
    "modelF.fit(X_train_norm, trainY, \n",
    "        validation_data=(X_test_norm, testY), \n",
    "        epochs=50,\n",
    "        batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Predict the results using 0.5 as a threshold (5 points) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelF.predict(X_test_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prediction:  [[0.96068287 0.04164359]\n",
      " [0.8932359  0.11107728]\n",
      " [0.9180343  0.07989183]\n",
      " [0.9247933  0.06762668]\n",
      " [0.8731804  0.12428898]\n",
      " [0.99569976 0.0046187 ]\n",
      " [0.65578705 0.32330742]\n",
      " [0.94420373 0.0561364 ]\n",
      " [0.76438737 0.24550492]\n",
      " [0.95779085 0.04308677]]\n"
     ]
    }
   ],
   "source": [
    "print(\" Prediction: \",y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_threshold = modelF.predict_proba(X_test_norm) > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Prediction with threshold:  [[ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True False]]\n"
     ]
    }
   ],
   "source": [
    "print(\" Prediction with threshold: \",y_pred_threshold[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "    \n",
    "We have predicted the results with and without specifying the threshold 0.5.\n",
    "\n",
    "Lets check the accuracy score and confusion matrix for the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Print the Accuracy score and confusion matrix (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for predictions with no specified thershold:  0.8588\n",
      "Accuracy score for predictions with specified threshold 0.5:  0.8588\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score for predictions without threshold\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"Accuracy score for predictions with no specified thershold: \", metrics.accuracy_score(testY, y_pred.round()))\n",
    "print(\"Accuracy score for predictions with specified threshold 0.5: \", metrics.accuracy_score(testY, y_pred_threshold.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for predictions with no specified threshold\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_neg</th>\n",
       "      <th>pred_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>1911</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>280</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_neg  pred_pos\n",
       "neg      1911        69\n",
       "pos       280       240"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Confusion Matrix for predictions with no specified threshold\")\n",
    "pd.DataFrame(metrics.confusion_matrix(testY.argmax(axis=1), y_pred.argmax(axis=1)),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for predictions with specified threshold 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_neg</th>\n",
       "      <th>pred_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>1920</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>280</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_neg  pred_pos\n",
       "neg      1920        60\n",
       "pos       280       240"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Confusion Matrix for predictions with specified threshold 0.5\")\n",
    "pd.DataFrame(metrics.confusion_matrix(testY.argmax(axis=1), y_pred_threshold.argmax(axis=1)),\n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for predictions with no specified threshold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92      1980\n",
      "           1       0.79      0.46      0.58       520\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      2500\n",
      "   macro avg       0.83      0.71      0.75      2500\n",
      "weighted avg       0.86      0.86      0.85      2500\n",
      " samples avg       0.86      0.86      0.86      2500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (\"Classification Report for predictions with no specified threshold\")\n",
    "print(classification_report(testY, y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for predictions with specified threshold 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92      1980\n",
      "           1       0.79      0.46      0.58       520\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      2500\n",
      "   macro avg       0.83      0.71      0.75      2500\n",
      "weighted avg       0.86      0.86      0.85      2500\n",
      " samples avg       0.86      0.86      0.86      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (\"Classification Report for predictions with specified threshold 0.5\")\n",
    "print(classification_report(testY, y_pred_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "For binary classification by default the threshold is 0.5. There is slight difference in the accuracy score or classification report with and without specifying the 0.5 threshold."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
